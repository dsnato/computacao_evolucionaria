"""
üìò DIA 11 ‚Äî Algoritmos Mem√©ticos (GA + Local Search)
----------------------------------------------------

Objetivo:
---------
Implementar um Algoritmo Mem√©tico (h√≠brido): um Algoritmo Gen√©tico real-valued
com a adi√ß√£o de uma busca local (hill-climbing / busca por vizinhan√ßa) aplicada
aos descendentes para refinar solu√ß√µes (memes = refinamentos locais).

Problema de teste:
------------------
O algoritmo otimiza a fun√ß√£o Rastrigin (multimodal) em dimens√£o D:
    f(x) = A*D + sum(x_i^2 - A*cos(2œÄ x_i)), com A=10
Objetivo: minimizar f(x) (m√≠nimo global em x=0 com f=0)

Caracter√≠sticas:
- Representa√ß√£o: vetor de floats (real-valued)
- Sele√ß√£o: torneio
- Crossover: blend arithmetic (real)
- Muta√ß√£o: gaussiana por dimens√£o
- Busca local: hill-climbing aleat√≥rio (pequenos passos gaussianos) aplicada com probabilidade LOCAL_SEARCH_PROB ao filho
- Elitismo: preserva melhores
- Sa√≠da: imprime progresso e plota converg√™ncia (melhor fitness por gera√ß√£o)
"""
import random
import math
import copy
import matplotlib.pyplot as plt

# -----------------------------
# 1) Hiperpar√¢metros
# -----------------------------
RANDOM_SEED = 42
random.seed(RANDOM_SEED)

POP_SIZE = 60              # popula√ß√£o
NUM_GENERATIONS = 120      # gera√ß√µes
DIM = 5                    # dimens√£o do problema (vetor x ‚àà R^DIM)
LOWER_BOUND = -5.12        # dom√≠nio Rastrigin
UPPER_BOUND = 5.12

TOURNAMENT_K = 3           # torneio
CROSSOVER_RATE = 0.9
MUTATION_RATE = 0.2        # probabilidade de mutar cada gene
MUTATION_STD = 0.2         # desvio-padr√£o da muta√ß√£o gaussiana

ELITE_SIZE = 2             # preserva os top N indiv√≠duos

LOCAL_SEARCH_PROB = 0.6    # probabilidade de aplicar busca local em um filho
LOCAL_SEARCH_ITERS = 20    # itera√ß√µes de hill-climbing por aplica√ß√£o
LOCAL_STEP_STD = 0.1       # escala dos passos locais (gaussiano)

# -----------------------------
# 2) Fun√ß√£o Rastrigin (a minimizar)
# -----------------------------
def rastrigin(x):
    """
    Rastrigin function: multimodal com muitos √≥timos locais.
    f(x) >= 0; f(0)=0.
    """
    A = 10.0
    return A * len(x) + sum([(xi ** 2 - A * math.cos(2 * math.pi * xi)) for xi in x])

# -----------------------------
# 3) Inicializa√ß√£o (popula√ß√£o de vetores reais)
# -----------------------------
def random_individual():
    """Cria indiv√≠duo aleat√≥rio (lista de floats de dimens√£o DIM)."""
    return [random.uniform(LOWER_BOUND, UPPER_BOUND) for _ in range(DIM)]

def initialize_population():
    return [random_individual() for _ in range(POP_SIZE)]

# -----------------------------
# 4) Avalia√ß√£o (fitness) - aqui, lower is better
# -----------------------------
def evaluate(individual):
    """Avalia um indiv√≠duo pela fun√ß√£o objetivo (fitness = valor a minimizar)."""
    return rastrigin(individual)

# -----------------------------
# 5) Sele√ß√£o: torneio
# -----------------------------
def tournament_selection(population, k=TOURNAMENT_K):
    """Retorna uma c√≥pia do vencedor do torneio (melhor entre k amostras)."""
    candidates = random.sample(population, k)
    winner = min(candidates, key=evaluate)  # min, pois queremos minimizar
    return copy.deepcopy(winner)

# -----------------------------
# 6) Crossover: blend/arithmetic
# -----------------------------
def blend_crossover(p1, p2, alpha=0.5):
    """
    BLX-like / arithmetic blend: cria um filho pontual entre p1 e p2.
    Simples: child = alpha*p1 + (1-alpha)*p2 (alpha sorteado).
    Retorna um √∫nico filho (pode-se criar 2 usando invers√£o de pais).
    """
    child = []
    for a, b in zip(p1, p2):
        a0 = min(a, b)
        b0 = max(a, b)
        # BLX-alpha-like sampling com extrapola√ß√£o controlada
        interval = b0 - a0
        low = a0 - alpha * interval
        high = b0 + alpha * interval
        val = random.uniform(low, high)
        # clamp para limites definidos
        val = max(min(val, UPPER_BOUND), LOWER_BOUND)
        child.append(val)
    return child

# -----------------------------
# 7) Muta√ß√£o gaussiana (per-gene)
# -----------------------------
def mutate(individual):
    """Aplica muta√ß√£o gaussiana por gene com probabilidade MUTATION_RATE."""
    mutant = []
    for gene in individual:
        if random.random() < MUTATION_RATE:
            gene = gene + random.gauss(0, MUTATION_STD)
        # garante limites
        gene = max(min(gene, UPPER_BOUND), LOWER_BOUND)
        mutant.append(gene)
    return mutant

# -----------------------------
# 8) Busca local (hill-climbing aleat√≥rio)
# -----------------------------
def local_search_hillclimb(individual, iters=LOCAL_SEARCH_ITERS, step_std=LOCAL_STEP_STD):
    """
    Aplica uma busca local simples: em cada itera√ß√£o gera uma vizinhan√ßa
    por pequenos passos gaussianos; se encontrar vizinho melhor (menor fitness),
    aceita o vizinho. Retorna indiv√≠duo refinado.
    """
    current = copy.deepcopy(individual)
    current_f = evaluate(current)

    for _ in range(iters):
        # gera vizinho por perturba√ß√£o gaussiana
        neighbor = [max(min(g + random.gauss(0, step_std), UPPER_BOUND), LOWER_BOUND) for g in current]
        neighbor_f = evaluate(neighbor)
        if neighbor_f < current_f:
            current, current_f = neighbor, neighbor_f
    return current

# -----------------------------
# 9) Gera√ß√£o nova com elitismo + mem√©tica
# -----------------------------
def create_new_generation(population):
    """
    Gera nova popula√ß√£o:
      - preserva elites
      - cria filhos por sele√ß√£o, crossover, muta√ß√£o
      - aplica busca local em alguns filhos (memetic refinement)
    """
    # ordena popula√ß√£o pelo fitness (menor √© melhor)
    sorted_pop = sorted(population, key=evaluate)
    new_pop = [copy.deepcopy(ind) for ind in sorted_pop[:ELITE_SIZE]]  # preserva elites

    while len(new_pop) < POP_SIZE:
        # sele√ß√£o de pais
        parent1 = tournament_selection(population)
        parent2 = tournament_selection(population)

        # crossover (com probabilidade)
        if random.random() < CROSSOVER_RATE:
            child = blend_crossover(parent1, parent2)
        else:
            # sem crossover, copia um dos pais
            child = copy.deepcopy(parent1 if random.random() < 0.5 else parent2)

        # muta√ß√£o
        child = mutate(child)

        # busca local (mem√©tica) com probabilidade
        if random.random() < LOCAL_SEARCH_PROB:
            child = local_search_hillclimb(child)

        new_pop.append(child)

    return new_pop[:POP_SIZE]

# -----------------------------
# 10) Loop principal do Algoritmo Mem√©tico
# -----------------------------
def memetic_algorithm():
    population = initialize_population()
    best_history = []

    for gen in range(1, NUM_GENERATIONS + 1):
        # registra melhor atual
        best = min(population, key=evaluate)
        best_f = evaluate(best)
        best_history.append(best_f)

        if gen % 10 == 0 or gen == 1:
            print(f"Gera√ß√£o {gen:03d} | Melhor fitness (m√≠n) = {best_f:.6f}")

        # gerar pr√≥xima gera√ß√£o
        population = create_new_generation(population)

    # retorno do melhor e hist√≥rico
    best = min(population, key=evaluate)
    return best, best_history

# -----------------------------
# 11) Execu√ß√£o do experimento
# -----------------------------
if __name__ == "__main__":
    best_ind, history = memetic_algorithm()

    print("\nMelhor indiv√≠duo encontrado:")
    print([round(v, 6) for v in best_ind])
    print("Fitness (Rastrigin) =", evaluate(best_ind))

    # plot da converg√™ncia (menor fitness por gera√ß√£o)
    plt.figure(figsize=(9, 4))
    plt.plot(history, label="Melhor fitness (m√≠n) por gera√ß√£o")
    plt.xlabel("Gera√ß√£o")
    plt.ylabel("Fitness (Rastrigin) ‚Äî menor √© melhor")
    plt.title("Algoritmo Mem√©tico ‚Äî GA + Busca Local")
    plt.grid(True)
    plt.legend()
    plt.show()


